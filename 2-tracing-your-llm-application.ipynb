{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing Your LLM Application\n",
    "\n",
    "In this notebook, we are building and instrumenting a simple LLM application that takes a query about art and feeds it into the Metropolitan Museum of Art API to get a list of relevant artwork.\n",
    "\n",
    "#### Learning goals:\n",
    "- How to create a span for LLM Observability\n",
    "- How to annotate a span with inputs and outputs\n",
    "- Different types of spans, including `tool`, `llm`, and `workflow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LLMObs.enable(\n",
    "    api_key=os.environ.get(\"DD_API_KEY\"),\n",
    "    site=os.environ.get(\"DD_SITE\", \"datadoghq.com\"),\n",
    "    ml_app=\"test-onboarding-app\",\n",
    "    agentless_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The steps to this simple workflow are:\n",
    "\n",
    "1. Take a question from a user, and parse it into an artwork query using OpenAI.\n",
    "2. Send the parsed query to the [Metropolitan Museum of Art API](https://metmuseum.github.io/#search).\n",
    "3. Return a list of URLs to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful constants\n",
    "\n",
    "SEARCH_ENDPOINT = \"https://collectionapi.metmuseum.org/public/collection/v1/search\"\n",
    "MAX_RESULTS = 5\n",
    "\n",
    "# https://metmuseum.github.io/#search\n",
    "fetch_met_urls_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"fetch_met_urls\",\n",
    "        \"description\": \"Submits a query to the MET API and returns urls of relevant artworks\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query_parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"q\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Represents the users query. Required. Add as many search terms from the query as you can. 'medieval portraits', 'french impressionist paintings', etc.\",\n",
    "                        },\n",
    "                        \"title\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Limits the query to only apply to the title field.\",\n",
    "                        },\n",
    "                        \"tags\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Limits the query to only apply to the tags field.\",\n",
    "                        },\n",
    "                        \"isOnView\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Returns objects that match the query and are on view in the museum.\",\n",
    "                        },\n",
    "                        \"artistOrCulture\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Returns objects that match the query, specifically searching against the artist name or culture field for objects.\",\n",
    "                        },\n",
    "                        \"medium\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'Returns objects that match the query and are of the specified medium or object type. Examples include: \"Ceramics\", \"Furniture\", \"Paintings\", \"Sculpture\", \"Textiles\", etc.',\n",
    "                        },\n",
    "                        \"geoLocation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'Returns objects that match the query and the specified geographic location. Examples include: \"Europe\", \"France\", \"Paris\", \"China\", \"New York\", etc.',\n",
    "                        },\n",
    "                        \"dateBegin\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"You must use both dateBegin and dateEnd, or neither. Returns objects that match the query and fall between the dateBegin and dateEnd parameters. Examples include: dateBegin=1700&dateEnd=1800 for objects from 1700 A.D. to 1800 A.D., dateBegin=-100&dateEnd=100 for objects between 100 B.C. to 100 A.D.\",\n",
    "                        },\n",
    "                        \"dateEnd\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"You must use both dateBegin and dateEnd, or neither. Returns objects that match the query and fall between the dateBegin and dateEnd parameters. Examples include: dateBegin=1700&dateEnd=1800 for objects from 1700 A.D. to 1800 A.D., dateBegin=-100&dateEnd=100 for objects between 100 B.C. to 100 A.D.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"q\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tracing tool spans\n",
    "\n",
    "Below is a simple tool `fetch_met_urls()` to query the Met API's `/search` endpoint. We'll be instrumenting this function, as we can't rely on auto-instrumentation to capture this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_met_urls(query_parameters):\n",
    "    response = requests.get(SEARCH_ENDPOINT, params=query_parameters)\n",
    "    response.raise_for_status()\n",
    "    object_ids = response.json().get(\"objectIDs\")\n",
    "    objects_to_return = object_ids[:MAX_RESULTS] if object_ids else []\n",
    "    urls = [f\"https://www.metmuseum.org/art/collection/search/{objectId}\" for objectId in objects_to_return]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Trace the function**: we can instrument this `fetch_met_urls()` function as a tool span, which represents a call to an external web API (The Met API). We do this by importing from `ddtrace.llmobs.decorators` with our desired span decorator, which is `@tool()`, and applying that decorator over our `fetch_met_urls()` function.\n",
    "\n",
    "Learn more about tool spans and span kinds in our [docs](https://docs.datadoghq.com/tracing/llm_observability/span_kinds/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tool decorator and decorate your tool function.\n",
    "\n",
    "def fetch_met_urls(query_parameters):\n",
    "    response = requests.get(SEARCH_ENDPOINT, params=query_parameters)\n",
    "    response.raise_for_status()\n",
    "    object_ids = response.json().get(\"objectIDs\")\n",
    "    objects_to_return = object_ids[:MAX_RESULTS] if object_ids else []\n",
    "    urls = [f\"https://www.metmuseum.org/art/collection/search/{objectId}\" for objectId in objects_to_return]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Annotate the span**: we now have a span that covers that function's execution, but we can add some extra information to the span to be more useful to us. Let's use `LLMObs.annotate()` to capture the inputs and outputs to this query operation.\n",
    "\n",
    "*Hint*: The `LLMObs.annotate()` method takes in the following arguments: `input_data`, `output_data`, `metrics`, `metadata`, and `tags`.\n",
    "\n",
    "Learn more about annotating spans in our [docs](https://docs.datadoghq.com/tracing/llm_observability/sdk/#annotating-a-span)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_met_urls(query_parameters):\n",
    "    # We annotate the tool call with input_data here\n",
    "\n",
    "    response = requests.get(SEARCH_ENDPOINT, params=query_parameters)\n",
    "    response.raise_for_status()\n",
    "    object_ids = response.json().get(\"objectIDs\")\n",
    "    objects_to_return = object_ids[:MAX_RESULTS] if object_ids else []\n",
    "    urls = [f\"https://www.metmuseum.org/art/collection/search/{objectId}\" for objectId in objects_to_return]\n",
    "    # We annotate the tool call with output_data here\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Auto-instrumented LLM call\n",
    "\n",
    "Once again, we are using OpenAI, which is automatically instrumented, so no further annotation is required for `parse_query()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "oai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Example query inputs and outputs for the fetch_met_urls function:\n",
    "\n",
    "query: medieval french tapestry painting\n",
    "output: {'q': 'medieval french tapestry painting', geoLocation: 'France', medium: 'Textiles', dateBegin: 1000, dateEnd: 1500}\n",
    "\n",
    "query: etruscan urns\n",
    "output: {'q': 'etruscan urn', geoLocation: 'Italy', medium: 'Travertine'}\n",
    "\n",
    "query: Cambodian hats from the 18th and 19th centuries\n",
    "output: {'q': 'Cambodian hats', geolocation: 'Cambodia', 'dateBegin': 1700, 'dateEnd': 1900}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_query(message):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response_message = (\n",
    "        oai_client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            tools=[fetch_met_urls_schema],\n",
    "            # https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice\n",
    "            tool_choice={\"type\": \"function\", \"function\": {\"name\": \"fetch_met_urls\"}},\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message\n",
    "    )\n",
    "    if response_message.tool_calls:\n",
    "        arguments = json.loads(response_message.tool_calls[0].function.arguments)\n",
    "    return arguments[\"query_parameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tracing workflow spans\n",
    "\n",
    "Finally, we create a `find_artworks` function here ties the `fetch_met_urls()` tool and `parse_query()` LLM call together. Since this operation involves a sequence of operations which include LLM calls and any supporting operations, we can call this a **workflow**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_artworks(question):\n",
    "    query = parse_query(question)\n",
    "    print(\"Parsed query parameters\", query)\n",
    "    urls = fetch_met_urls(query)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Trace the function**: we can instrument this function as a workflow span, similar to how we traced `fetch_met_urls()`.\n",
    "\n",
    "Learn more about workflow spans in our [docs](https://docs.datadoghq.com/tracing/llm_observability/sdk/#workflow-span)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the workflow decorator and decorate your workflow function.\n",
    "\n",
    "\n",
    "def find_artworks(question):\n",
    "    query = parse_query(question)\n",
    "    print(\"Parsed query parameters\", query)\n",
    "    urls = fetch_met_urls(query)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Annotate your span**: like before, let's annotate the workflow span so that we can see the inputs and outputs of your LLM application on a more granular level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_artworks(question):\n",
    "    # We annotate the workflow span with input_data here\n",
    "    query = parse_query(question)\n",
    "    print(\"Parsed query parameters\", query)\n",
    "    urls = fetch_met_urls(query)\n",
    "    # We annotate the workflow span with output_data here\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your LLM application\n",
    "\n",
    "Now that your application is instrumented, let's try running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed query parameters {'q': 'french revolution', 'medium': 'Paintings', 'dateBegin': 1789, 'dateEnd': 1799}\n"
     ]
    }
   ],
   "source": [
    "urls = find_artworks(\"paintings of the french revolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.metmuseum.org/art/collection/search/437885',\n",
      " 'https://www.metmuseum.org/art/collection/search/436875',\n",
      " 'https://www.metmuseum.org/art/collection/search/436222',\n",
      " 'https://www.metmuseum.org/art/collection/search/726543']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the trace in Datadog\n",
    "\n",
    "Now, try checking out the [LLM Observability interface](https://app.datadoghq.com/llm) in Datadog. You should see a trace that describes the workflow we just ran.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "\n",
    "The following cells install dependencies and set up LLM tracing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required env vars for ddtrace\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddtrace.auto\n",
    "\n",
    "ddtrace.patch_all()\n",
    "\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "LLMObs.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a weather forecasting agent\n",
    "\n",
    "In the next cells we build the logic for a basic agent that can answer questions about the weather. The code for the agent is adapted from Peter Roelants' excellent blog post [\"Implement a simple ReAct Agent using OpenAI function calling\"](https://peterroelants.github.io/posts/react-openai-function-calling/).\n",
    "\n",
    "First, we create a system prompt that initiates some basic ReAct agent logic:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant who can answer multistep questions by sequentially calling functions. \n",
    "\n",
    "Follow a pattern of THOUGHT (reason step-by-step about which function to call next),\n",
    "ACTION (call a function to as a next step towards the final answer), \n",
    "OBSERVATION (output of the function).\n",
    "\n",
    "Reason step by step which actions to take to get to the answer. \n",
    "Only call functions with arguments coming verbatim from the user or the output of other functions.\",\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_initial_messages(question_prompt):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question_prompt,\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define some tools that we want the agent to have access to:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "FORECAST_API_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "CURRENT_LOCATION_BY_IP_URL = \"http://ip-api.com/json?fields=lat,lon\"\n",
    "\n",
    "\n",
    "def get_current_location():\n",
    "    time.sleep(1)  # simulate a longer task\n",
    "    return json.dumps(requests.get(CURRENT_LOCATION_BY_IP_URL).json())\n",
    "\n",
    "\n",
    "def get_current_weather(latitude, longitude, temperature_unit):\n",
    "    time.sleep(1)  # simulate a longer task\n",
    "    resp = requests.get(\n",
    "        FORECAST_API_URL,\n",
    "        params={\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"temperature_unit\": temperature_unit,\n",
    "            \"current_weather\": True,\n",
    "        },\n",
    "    )\n",
    "    return json.dumps(resp.json())\n",
    "\n",
    "\n",
    "def calculate(formula):\n",
    "    return str(eval(formula))\n",
    "\n",
    "\n",
    "class StopException(Exception):\n",
    "    \"\"\"\n",
    "    Signal that the task is finished.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def finish(answer):\n",
    "    raise StopException(answer)\n",
    "\n",
    "\n",
    "available_functions = {\n",
    "    \"get_current_location\": get_current_location,\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "    \"calculate\": calculate,\n",
    "    \"finish\": finish,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a json schema in the `available_functions` array to describe each function. We'll pass this to the agent:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_schema = [\n",
    "    {\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_location\",\n",
    "            \"description\": \"Get the current location of the user.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []},\n",
    "        },\n",
    "        \"type\": \"function\",\n",
    "    },\n",
    "    {\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\"type\": \"number\"},\n",
    "                    \"longitude\": {\"type\": \"number\"},\n",
    "                    \"temperature_unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\", \"temperature_unit\"],\n",
    "            },\n",
    "        },\n",
    "        \"type\": \"function\",\n",
    "    },\n",
    "    {\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Calculate the result of a given formula.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"formula\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Numerical expression to compute the result of, in Python syntax.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"formula\"],\n",
    "            },\n",
    "        },\n",
    "        \"type\": \"function\",\n",
    "    },\n",
    "    {\n",
    "        \"function\": {\n",
    "            \"name\": \"finish\",\n",
    "            \"description\": \"Once you have the information required, answer the user's original question, and finish the conversation.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"answer\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Answer to the user's question.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"answer\"],\n",
    "            },\n",
    "        },\n",
    "        \"type\": \"function\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate our openai client:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "oai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function called `execute_loop_step` that handles the recursive agent logic. In the function, we:\n",
    "\n",
    "1. call the model with the previous messages append a message to the messages array, and feed the new messages array into the subsequent call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddtrace.llmobs.decorators import *\n",
    "\n",
    "MAX_CALLS = 4\n",
    "MODEL = \"gpt-4\"\n",
    "\n",
    "\n",
    "@workflow(\"execute_loop_step\")\n",
    "def execute_loop_step(messages, calls_left=MAX_CALLS):\n",
    "    if calls_left < 1:\n",
    "        return messages\n",
    "    # https://platform.openai.com/docs/api-reference/chat/create#chat-create-messages\n",
    "    response = oai_client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=function_schema,\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    if response_message.content:\n",
    "        print(\"\\n\")\n",
    "        print(response_message.content)\n",
    "    if response_message.tool_calls:\n",
    "        print(\"\\n\")\n",
    "        print(\"CALL TOOL:\", [str(t) for t in response_message.tool_calls])\n",
    "    messages.append(response_message)\n",
    "    if not response_message.tool_calls:\n",
    "        return execute_loop_step(messages, calls_left - 1)\n",
    "\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        # define a small helper function to reduce repetitive code\n",
    "        def append_tool_message_and_execute_loop(content):\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": content,\n",
    "                }\n",
    "            )\n",
    "            return execute_loop_step(messages, calls_left - 1)\n",
    "\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        if function_to_call is None:\n",
    "            return append_tool_message_and_execute_loop(\n",
    "                f\"Invalid function name: {function_name!r}\"\n",
    "            )\n",
    "        try:\n",
    "            function_args_dict = json.loads(tool_call.function.arguments)\n",
    "        except json.JSONDecodeError as exc:\n",
    "            return append_tool_message_and_execute_loop(\n",
    "                f\"Error decoding function call `{function_name}` arguments {tool_call.function.arguments!r}! Error: {exc!s}\"\n",
    "            )\n",
    "        try:\n",
    "            with LLMObs.tool(function_name):\n",
    "                LLMObs.annotate(input_data=function_args_dict)\n",
    "                function_response = function_to_call(**function_args_dict)\n",
    "                LLMObs.annotate(output_data=function_response)\n",
    "            return append_tool_message_and_execute_loop(function_response)\n",
    "        except StopException as answer:\n",
    "            return str(answer)\n",
    "        except Exception as exc:\n",
    "            # LLMObs._instance.tracer.current_span.set_exc_info(**sys.exc_info())\n",
    "            return append_tool_message_and_execute_loop(\n",
    "                f\"Error calling function `{function_name}`: {type(exc).__name__}: {exc!s}!\"\n",
    "            )\n",
    "    return \"no answer found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create the top-level function to take a prompt from a user, call the agent, and return a response:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent(name=\"weather_assistant\")\n",
    "def call_weather_assistant(question_prompt):\n",
    "    LLMObs.annotate(\n",
    "        input_data=question_prompt,\n",
    "    )\n",
    "    messages = get_initial_messages(question_prompt)\n",
    "    answer = execute_loop_step(messages)\n",
    "    LLMObs.annotate(\n",
    "        output_data=answer,\n",
    "    )\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can ask the weather assistant questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_weather_assistant(\n",
    "    \"What is the weather in my current location? Please give me the temperature in farenheit. Also tell me my current location coordinates.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

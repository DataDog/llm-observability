{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup below shows in-code configuration. For most applications, we can also enable LLMObs simply by calling `ddtrace-run` with the appropriate env vars, [as seen here in our quickstart instructions](https://docs.datadoghq.com/tracing/llm_observability/quickstart/).\n",
    "\n",
    "The code below requires you to have created an `.env` file with a `DD_API_KEY` and if necessary a `DD_SITE` as explained in the README.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "enable() got an unexpected keyword argument 'dd_api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mddtrace\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllmobs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMObs\n\u001b[1;32m      6\u001b[0m ddtrace\u001b[38;5;241m.\u001b[39mpatch_all()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mLLMObs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdd_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdotenv_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDD_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdd_site\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdotenv_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDD_SITE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatadoghq.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mml_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest-onboarding-app\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdd_llmobs_no_apm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: enable() got an unexpected keyword argument 'dd_api_key'"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "import ddtrace.auto\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "ddtrace.patch_all()\n",
    "\n",
    "LLMObs.enable(\n",
    "    dd_api_key=dotenv_values(\".env\")[\"DD_API_KEY\"],\n",
    "    dd_site=dotenv_values(\".env\").get(\"DD_SITE\", \"datadoghq.com\"),\n",
    "    ml_app=\"test-onboarding-app\",\n",
    "    dd_llmobs_no_apm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing an LLM Call\n",
    "\n",
    "An LLM Span represents a call to a model. In this simple example, we are asking `gpt-3.5-turbo` to summarize a provided text and identify a list of topics from the text.\n",
    "\n",
    "Because we use OpenAI, the call to the LLM is instrumented automatically by Datadog:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "oai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "Your task is to \n",
    "1. Summarize the given text at a 6th grade reading level in no more than 2 sentences.\n",
    "2. Identify what topics the text belongs to that would allow you to categorize it in a school library.\n",
    "Format your output strictly following this JSON convention:\n",
    "{\t\n",
    "    \"topics\": <[insert array of topics here]>\n",
    "    \"summary\": <insert summary here>\n",
    "}\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "def summarize(text, prompt=sys_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    # llm span auto-instrumented via our openai integration\n",
    "    return (\n",
    "        oai_client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "ONE JANUARY day, thirty years ago, the little town of Hanover, anchored on a windy Nebraska tableland, was trying not to be blown away. A mist of fine snowflakes was curling and eddying about the cluster of low drab buildings huddled on the gray prairie, under a gray sky. The dwelling-houses were set about haphazard on the tough prairie sod; some of them looked as if they had been moved in overnight, and others as if they were straying off by themselves, headed straight for the open plain. None of them had any appearance of permanence, and the howling wind blew under them as well as over them. The main street was a deeply rutted road, now frozen hard, which ran from the squat red railway station and the grain \"elevator\" at the north end of the town to the lumber yard and the horse pond at the south end. On either side of this road straggled two uneven rows of wooden buildings; the general merchandise stores, the two banks, the drug store, the feed store, the saloon, the post-office. The board sidewalks were gray with trampled snow, but at two o'clock in the afternoon the shopkeepers, having come back from dinner, were keeping well behind their frosty windows.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error submitting packet: [Errno 61] Connection refused, dropping the packet and closing the socket, 2 additional messages skipped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'topics': [],\n",
       " 'summary': 'The text does not provide any information to summarize.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# print out the LLM's response:\n",
    "json.loads(summarize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try checking out the LLM Observability interace in Datadog. You should see a trace that describes the LLM call, including the system prompt, the user prompt, and the response.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

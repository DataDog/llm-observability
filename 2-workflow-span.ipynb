{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required env vars for ddtrace\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ddtrace.auto\n",
    "\n",
    "ddtrace.patch_all()\n",
    "\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "LLMObs.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing a Workflow Span\n",
    "\n",
    "A workflow span reprsents a static sequence. In this example, we are:\n",
    "\n",
    "1. Taking a query from a user\n",
    "2. Parsing that quey in a call to openai\n",
    "3. Sending the parsed query to the Metropolitan Museum of Art API\n",
    "4. Returning a list of urls to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ddtrace.llmobs.decorators import tool\n",
    "import json\n",
    "\n",
    "\n",
    "# API docs: https://metmuseum.github.io/#search\n",
    "@tool(name=\"fetch_met_urls\")\n",
    "def fetch_met_urls(query):\n",
    "    base_url = \"https://collectionapi.metmuseum.org/public/collection/v1/search\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"hasImages\": \"true\",\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        objects = response.json()[\"objectIDs\"]\n",
    "        urls = [\n",
    "            f\"https://www.metmuseum.org/art/collection/search/{objectId}\"\n",
    "            for objectId in objects[:3]\n",
    "        ]\n",
    "        LLMObs.annotate(\n",
    "            input_data=query,\n",
    "            output_data=urls,\n",
    "        )\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        LLMObs.annotate(status=\"error\", error=e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from ddtrace.llmobs.decorators import workflow\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "oai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "\tYou are a service that provides information about the art in the collection of the Metropolitan Museum of Art.\n",
    "    You take a free text query and parse it into a format that can be sent to the Met API.\n",
    "    Parse a query out from the user's message in the following JSON format:\n",
    "\n",
    "    Prompt: I think I'd like to see some art from the 19th century. Ideally southern European or maybe Northern African.\n",
    "    Response: {\"query\": \"19th century southern European Northern African\"}\n",
    "\t\"\"\"\n",
    "\n",
    "\n",
    "def parse_query(message, prompt=sys_prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = (\n",
    "        oai_client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )\n",
    "    query = json.loads(response)[\"query\"]\n",
    "    print(f\"Parsed query: {query}\")\n",
    "    return query\n",
    "\n",
    "\n",
    "@workflow(name=\"get_art\")\n",
    "def get_art(question, prompt=sys_prompt):\n",
    "    query = parse_query(question, prompt)\n",
    "    urls = fetch_met_urls(query)\n",
    "    LLMObs.annotate(\n",
    "        input_data=question,\n",
    "        output_data=json.dumps(urls),\n",
    "    )\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_art(\"I think I'd like to see some art from China that features a cat or doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from ddtrace.llmobs import LLMObs\n",
    "\n",
    "LLMObs.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and tracing a simple LLM service\n",
    "\n",
    "In this notebook, we are building a service that takes a free text query about art from a user, and feeds it into the Metropolitan Museum of Art API to get a list of artwork.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Take a query from a user.\n",
    "2. Parse that query via a call to OpenAI.\n",
    "3. Send the parsed query to the [Metropolitan Museum of Art API](https://metmuseum.github.io/#search).\n",
    "4. Return a list of URLs to the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating the tool to fetch data from the Met API\n",
    "\n",
    "In the next cell, we create and instrument a \"tool\": a function that can send a query to the Met API's `/search` endpoint. The actual query will be created by an LLM call in a following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ddtrace.llmobs.decorators import *\n",
    "\n",
    "SEARCH_ENDPOINT = \"https://collectionapi.metmuseum.org/public/collection/v1/search\"\n",
    "MAX_RESULTS = 5\n",
    "\n",
    "\n",
    "# learn more about tool calls in our docs:\n",
    "# https://docs.datadoghq.com/tracing/llm_observability/sdk/#tool-span\n",
    "\n",
    "\n",
    "@tool()\n",
    "def fetch_met_urls(query_parameters):\n",
    "    # We annotate the tool call with input_data here\n",
    "    LLMObs.annotate(\n",
    "        input_data=query_parameters,\n",
    "    )\n",
    "    response = requests.get(SEARCH_ENDPOINT, params=query_parameters)\n",
    "    response.raise_for_status()\n",
    "    object_ids = response.json().get(\"objectIDs\")\n",
    "    objects_to_return = object_ids[:MAX_RESULTS] if object_ids else []\n",
    "    urls = [\n",
    "        f\"https://www.metmuseum.org/art/collection/search/{objectId}\"\n",
    "        for objectId in objects_to_return\n",
    "    ]\n",
    "    # We annotate the tool call with output_data here\n",
    "    LLMObs.annotate(\n",
    "        output_data=urls,\n",
    "    )\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://metmuseum.github.io/#search\n",
    "fetch_met_urls_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"fetch_met_urls\",\n",
    "        \"description\": \"Submits a query to the MET API and returns urls of relevant artworks\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query_parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"q\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Represents the users query. Required. Add as many search terms from the query as you can. 'medieval portraits', 'french impressionist paintings', etc.\",\n",
    "                        },\n",
    "                        \"title\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Limits the query to only apply to the title field.\",\n",
    "                        },\n",
    "                        \"tags\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Limits the query to only apply to the tags field.\",\n",
    "                        },\n",
    "                        \"isOnView\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Returns objects that match the query and are on view in the museum.\",\n",
    "                        },\n",
    "                        \"artistOrCulture\": {\n",
    "                            \"type\": \"boolean\",\n",
    "                            \"description\": \"Returns objects that match the query, specifically searching against the artist name or culture field for objects.\",\n",
    "                        },\n",
    "                        \"medium\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'Returns objects that match the query and are of the specified medium or object type. Examples include: \"Ceramics\", \"Furniture\", \"Paintings\", \"Sculpture\", \"Textiles\", etc.',\n",
    "                        },\n",
    "                        \"geoLocation\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": 'Returns objects that match the query and the specified geographic location. Examples include: \"Europe\", \"France\", \"Paris\", \"China\", \"New York\", etc.',\n",
    "                        },\n",
    "                        \"dateBegin\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"You must use both dateBegin and dateEnd, or neither. Returns objects that match the query and fall between the dateBegin and dateEnd parameters. Examples include: dateBegin=1700&dateEnd=1800 for objects from 1700 A.D. to 1800 A.D., dateBegin=-100&dateEnd=100 for objects between 100 B.C. to 100 A.D.\",\n",
    "                        },\n",
    "                        \"dateEnd\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"You must use both dateBegin and dateEnd, or neither. Returns objects that match the query and fall between the dateBegin and dateEnd parameters. Examples include: dateBegin=1700&dateEnd=1800 for objects from 1700 A.D. to 1800 A.D., dateBegin=-100&dateEnd=100 for objects between 100 B.C. to 100 A.D.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"q\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating an LLM call to handle parsing user input into a standardized query\n",
    "\n",
    "Once again, we are using OpenAI, which is automatically instrumented, so no further annotation is required:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "oai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Example query inputs and outputs for the fetch_met_urls function:\n",
    "\n",
    "query: medieval french tapestry painting\n",
    "output: {'q': 'medieval french tapestry painting', geoLocation: 'France', medium: 'Textiles', dateBegin: 1000, dateEnd: 1500}\n",
    "\n",
    "query: etruscan urns\n",
    "output: {'q': 'etruscan urn', geoLocation: 'Italy', medium: 'Travertine'}\n",
    "\n",
    "query: Cambodian hats from the 18th and 19th centuries\n",
    "output: {'q': 'Cambodian hats', geolocation: 'Cambodia', 'dateBegin': 1700, 'dateEnd': 1900}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_query(message):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response_message = (\n",
    "        oai_client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            tools=[fetch_met_urls_schema],\n",
    "            # https://platform.openai.com/docs/api-reference/chat/create#chat-create-tool_choice\n",
    "            tool_choice={\"type\": \"function\", \"function\": {\"name\": \"fetch_met_urls\"}},\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message\n",
    "    )\n",
    "    if response_message.tool_calls:\n",
    "        arguments = json.loads(response_message.tool_calls[0].function.arguments)\n",
    "    return arguments[\"query_parameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creating the `find_artworks` function\n",
    "\n",
    "Finally, we create a `find_artworks` function here ties the LLM call and tool call together. We annotate this as a workflow span:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn more about workflow spans in our docs:\n",
    "# https://docs.datadoghq.com/tracing/llm_observability/sdk/#workflow-span\n",
    "@workflow()\n",
    "def find_artworks(question):\n",
    "    # We annotate the workflow span with input_data here\n",
    "    LLMObs.annotate(\n",
    "        input_data=question,\n",
    "    )\n",
    "    query = parse_query(question)\n",
    "    print(\"Parsed query parameters\", query)\n",
    "    urls = fetch_met_urls(query)\n",
    "    # We annotate the workflow span with output_data here\n",
    "    LLMObs.annotate(\n",
    "        output_data=urls,\n",
    "    )\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed query parameters {'q': 'french revolution', 'medium': 'Paintings'}\n"
     ]
    }
   ],
   "source": [
    "urls = find_artworks(\"paintings of the french revolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.metmuseum.org/art/collection/search/488319',\n",
      " 'https://www.metmuseum.org/art/collection/search/437925',\n",
      " 'https://www.metmuseum.org/art/collection/search/436106',\n",
      " 'https://www.metmuseum.org/art/collection/search/789578',\n",
      " 'https://www.metmuseum.org/art/collection/search/436840']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pp(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the trace in Datadog\n",
    "\n",
    "Now, try checking out the [LLM Observability interface](https://app.datadoghq.com/llm) in Datadog. You should see a trace that describes the workflow we just ran.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
